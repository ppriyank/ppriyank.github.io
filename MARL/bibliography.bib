@article{ddrqn,
  title={Learning to Communicate to Solve Riddles with Deep Distributed Recurrent Q-Networks},
  author={Jakob N. Foerster, Yannis M. Assael, Nando de Freitas, Shimon Whiteson},
  journal={arXivreprint arXiv:1602.02672},
  year={2016},
  url={https://arxiv.org/abs/1602.02672}
}

@article{hausknecht,
  title={Cooperation and Communication in Multiagent Deep Reinforcement Learning},
  author={Matthew John Hausknecht},
  journal={UT Electronic Theses and Dissertations},
  year={2016},
  url={https://repositories.lib.utexas.edu/handle/2152/45681}
}


@article{RIALDIAL,
  title={Learning to Communicate with
Deep Multi-Agent Reinforcement Learning},
  author={Jakob Foerster,Yannis Assael,Nando de Freitas,Shimon Whiteson},
  journal={UT Electronic Theses and Dissertations},
  year={2016},
  url={https://repositories.lib.utexas.edu/handle/2152/45681}
}

@article{Mnih,
  title={Human-level control through deep reinforcement
learning},
  author={Volodymyr Mnih, et al},
  year={2015},
  url={https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf}
}

@article{Nguyen,
  title={Deep Reinforcement Learning for Multi-Agent Systems: A
Review of Challenges, Solutions and Applications},
  author={Thanh Thi Nguyen,Ngoc Duy Nguyen, Saeid Nahavandi},
  year={2019},
  url={https://arxiv.org/pdf/1812.11794.pdf}
}

@article{castaneda,
  title={Deep Reinforcement Learning Variants of Multi-Agent Learning Algorithms},
  author={Alvaro Ovalle Castaneda},
  year={2016},
  url={https://project-archive.inf.ed.ac.uk/msc/20162091/msc_proj.pdf}
}

@misc{DeepDeterministicPolicyGradientsInTensorFlow,
  title={Deep Deterministic Policy Gradients in TensorFlow},
  author={Patrick Emami},
  year={2016},
  url={https://pemami4911.github.io/blog/2016/09/21/ddpg-rl.html}
}

@article{DeterministicPolicyGradientAlgorithms,
  title={Deterministic Policy Gradient Algorithms},
  author={David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, Martin Riedmiller},
  journal={Proceedings of Machine Learning Research},
  year={2013},
  url={https://pemami4911.github.io/blog/2016/09/21/ddpg-rl.html}
}

@article{MultiAgentActorCritic,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Ryan Lowe, Yi Wu, et al},
  journal={arXiv},
  year={2018},
  url={https://arxiv.org/pdf/1706.02275.pdf}
}

@misc{SolvingContinuousControl,
  title={Solving Continuous Control environment using Deep Deterministic Policy Gradient (DDPG) agent},
  author={Henry},
  year={2018},
  url={https://medium.com/@kinwo/solving-continuous-control-environment-using-deep-deterministic-policy-gradient-ddpg-agent-5e94f82f366d}
}

@article{Minimax,
  title={Robust Multi-Agent Reinforcement Learning via Minimax Deep Deterministic Policy Gradient},
  author={Shihui Li, Yi Wu, et al},
  journal={EECS},
  year={2019},
  url={https://people.eecs.berkeley.edu/~russell/papers/aaai19-marl.pdf}
}

@article{Communications,
  title={Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations},
  author={Ozel Kilinc and Giovanni Montana},
  journal={arXiv},
  year={2018},
  url={https://arxiv.org/pdf/1812.00922.pdf}
}

@ARTICLE{DecPOMDP,
author={X. {Jiang} and X. {Wang} and H. {Xi} and F. {Liu}},
journal={IEEE Transactions on Automatic Control},
title={Centralized Optimization for Dec-POMDPs Under the Expected Average Reward Criterion},
year={2017},
volume={62},
number={11},
pages={6032-6038},
keywords={decision theory;estimation theory;gradient methods;Markov processes;optimisation;state estimation;system state estimation;Dec-POMDP framework;decentralized observation-based policy;expected average reward criterion;centralized optimization;gradient estimates;optimal policy;centralized stochastic gradient policy iteration algorithm;partially observable stochastic environment;action spaces;discrete state;decentralized partially observable Markov decision process;Optimization;Markov processes;Approximation algorithms;Dynamic programming;Process control;Algorithm design and analysis;Centralized optimization;decentralized partially observable Markov decision process (Dec-POMDP);large-scale system;sensitivity analysis;stochastic approximation},
doi={10.1109/TAC.2017.2702203},
ISSN={0018-9286},
month={Nov},}

@article{decentralized,
 author = {Oliehoek, Frans A. and Spaan, Matthijs T. J. and Vlassis, Nikos},
 title = {Optimal and Approximate Q-value Functions for Decentralized POMDPs},
 journal = {J. Artif. Int. Res.},
 volume = {32},
 number = {1},
 month = {may},
 year = {2008},
 issn = {1076-9757},
 pages = {289--353},
 numpages = {65},
 url = {http://dl.acm.org/citation.cfm?id=1622673.1622680},
 acmid = {1622680},
 publisher = {AI Access Foundation},
 address = {USA},
}

@article{lowe,
  author    = {Ryan Lowe and
               Yi Wu and
               Aviv Tamar and
               Jean Harb and
               Pieter Abbeel and
               Igor Mordatch},
  title     = {Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  journal   = {CoRR},
  volume    = {abs/1706.02275},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.02275},
  archivePrefix = {arXiv},
  eprint    = {1706.02275},
  timestamp = {Mon, 13 Aug 2018 16:47:09 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LoweWTHAM17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Kraemer,
  title={Multi-agent reinforcement learning as a rehearsal for decentralized planning},
  author={Landon Kraemer and Bikramjit Banerjee},
  journal={Neurocomputing},
  year={2016},
  volume={190},
  pages={82-94}
}

@article{eval,
  author    = {Jacopo Castellini and
               Frans A. Oliehoek and
               Rahul Savani and
               Shimon Whiteson},
  title     = {The Representational Capacity of Action-Value Networks for Multi-Agent
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1902.07497},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.07497},
  archivePrefix = {arXiv},
  eprint    = {1902.07497},
  timestamp = {Sat, 02 Mar 2019 16:35:38 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1902-07497},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{qmix,
  author    = {Tabish Rashid and
               Mikayel Samvelyan and
               Christian Schr{\"{o}}der de Witt and
               Gregory Farquhar and
               Jakob N. Foerster and
               Shimon Whiteson},
  title     = {{QMIX:} Monotonic Value Function Factorisation for Deep Multi-Agent
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1803.11485},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.11485},
  archivePrefix = {arXiv},
  eprint    = {1803.11485},
  timestamp = {Mon, 13 Aug 2018 16:46:51 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1803-11485},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{centralized,
    author = {Carlos Guestrin and Michail Lagoudakis and Ronald Parr},
    title = {Coordinated Reinforcement Learning},
    booktitle = {In Proceedings of the ICML-2002 The Nineteenth International Conference on Machine Learning},
    year = {2002},
    pages = {227--234}
}

@inproceedings{sparse,
 author = {Kok, Jelle R. and Vlassis, Nikos},
 title = {Sparse Cooperative Q-learning},
 booktitle = {Proceedings of the Twenty-first International Conference on Machine Learning},
 series = {ICML '04},
 year = {2004},
 isbn = {1-58113-838-5},
 location = {Banff, Alberta, Canada},
 pages = {61--},
 url = {http://doi.acm.org/10.1145/1015330.1015410},
 doi = {10.1145/1015330.1015410},
 acmid = {1015410},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@incollection{iql,
 author = {Tan, Ming},
 chapter = {Multi-agent Reinforcement Learning: Independent vs. Cooperative Agents},
 title = {Readings in Agents},
 editor = {Huhns, Michael N. and Singh, Munindar P.},
 year = {1998},
 isbn = {1-55860-495-2},
 pages = {487--494},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=284860.284934},
 acmid = {284934},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
}


@article{coma,
  author    = {Jakob N. Foerster and
               Gregory Farquhar and
               Triantafyllos Afouras and
               Nantas Nardelli and
               Shimon Whiteson},
  title     = {Counterfactual Multi-Agent Policy Gradients},
  journal   = {CoRR},
  volume    = {abs/1705.08926},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.08926},
  archivePrefix = {arXiv},
  eprint    = {1705.08926},
  timestamp = {Mon, 13 Aug 2018 16:47:20 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/FoersterFANW17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{vdn,
  author    = {Peter Sunehag and
               Guy Lever and
               Audrunas Gruslys and
               Wojciech Marian Czarnecki and
               Vin{\'{\i}}cius Flores Zambaldi and
               Max Jaderberg and
               Marc Lanctot and
               Nicolas Sonnerat and
               Joel Z. Leibo and
               Karl Tuyls and
               Thore Graepel},
  title     = {Value-Decomposition Networks For Cooperative Multi-Agent Learning},
  journal   = {CoRR},
  volume    = {abs/1706.05296},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.05296},
  archivePrefix = {arXiv},
  eprint    = {1706.05296},
  timestamp = {Mon, 13 Aug 2018 16:46:26 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SunehagLGCZJLSL17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{gupta,
author="Gupta, Jayesh K.
and Egorov, Maxim
and Kochenderfer, Mykel",
editor="Sukthankar, Gita
and Rodriguez-Aguilar, Juan A.",
title="Cooperative Multi-agent Control Using Deep Reinforcement Learning",
booktitle="Autonomous Agents and Multiagent Systems",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="66--83",
isbn="978-3-319-71682-4"
}

@article{dqrn,
  author    = {Matthew J. Hausknecht and
               Peter Stone},
  title     = {Deep Recurrent Q-Learning for Partially Observable MDPs},
  journal   = {CoRR},
  volume    = {abs/1507.06527},
  year      = {2015},
  url       = {http://arxiv.org/abs/1507.06527},
  archivePrefix = {arXiv},
  eprint    = {1507.06527},
  timestamp = {Mon, 13 Aug 2018 16:48:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HausknechtS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Dugas,
    author = {Dugas, Charles and Bengio, Yoshua and Belisle, Francois and Nadeau, Claude and Garcia, Rene},
     month = {jun},
     title = {Incorporating Functional Knowledge in Neural Networks},
   journal = {The Journal of Machine Learning Research},
    volume = {10},
      year = {2009},
     pages = {1239--1262},
  abstract = {Incorporating prior knowledge of a particular task into the architecture of a learning algorithm can greatly improve generalization performance. We study here a case where we know that the function to be learned is non-decreasing in its two arguments and convex in one of them. For this purpose we propose a class of functions similar to multi-layer neural networks but (1) that has those properties, (2) is a universal approximator of Lipschitz functions with these and other properties. We apply this new class of functions to the task of modelling the price of call options. Experiments show improvements on regressing the price of call options using the new types of function classes that incorporate the a priori constraints.}
}


@article{starcraft,
  author    = {Mikayel Samvelyan and
               Tabish Rashid and
               Christian Schr{\"{o}}der de Witt and
               Gregory Farquhar and
               Nantas Nardelli and
               Tim G. J. Rudner and
               Chia{-}Man Hung and
               Philip H. S. Torr and
               Jakob N. Foerster and
               Shimon Whiteson},
  title     = {The StarCraft Multi-Agent Challenge},
  journal   = {CoRR},
  volume    = {abs/1902.04043},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.04043},
  archivePrefix = {arXiv},
  eprint    = {1902.04043},
  timestamp = {Sat, 02 Mar 2019 16:35:38 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1902-04043},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{star,
  author    = {Oriol Vinyals and
               Timo Ewalds and
               Sergey Bartunov and
               Petko Georgiev and
               Alexander Sasha Vezhnevets and
               Michelle Yeo and
               Alireza Makhzani and
               Heinrich K{\"{u}}ttler and
               John Agapiou and
               Julian Schrittwieser and
               John Quan and
               Stephen Gaffney and
               Stig Petersen and
               Karen Simonyan and
               Tom Schaul and
               Hado van Hasselt and
               David Silver and
               Timothy P. Lillicrap and
               Kevin Calderone and
               Paul Keet and
               Anthony Brunasso and
               David Lawrence and
               Anders Ekermo and
               Jacob Repp and
               Rodney Tsing},
  title     = {StarCraft {II:} {A} New Challenge for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1708.04782},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.04782},
  archivePrefix = {arXiv},
  eprint    = {1708.04782},
  timestamp = {Mon, 13 Aug 2018 16:47:24 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-04782},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{alpha,
  author    = {
Oriol Vinyals, Igor Babuschkin, Junyoung Chung, Michael Mathieu, Max Jaderberg, Wojtek Czarnecki, Andrew Dudzik, Aja Huang, Petko Georgiev, Richard Powell, Timo Ewalds, Dan Horgan, Manuel Kroiss, Ivo Danihelka, John Agapiou, Junhyuk Oh, Valentin Dalibard, David Choi, Laurent Sifre, Yury Sulsky, Sasha Vezhnevets, James Molloy, Trevor Cai, David Budden, Tom Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff, Toby Pohlen, Yuhuai Wu, Dani Yogatama, Julia Cohen, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap, Chris Apps, Koray Kavukcuoglu, Demis Hassabis, David Silver},
  title     = {AlphaStar: Mastering the Real-Time Strategy Game StarCraft II},
  year      = {2019},
  url       = {https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/}
}


@article{lstm,
 author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
 title = {Long Short-Term Memory},
 journal = {Neural Comput.},
 date = {November 15, 1997},
 volume = {9},
 number = {8},
 month = {nov},
 year = {1997},
 issn = {0899-7667},
 pages = {1735--1780},
 numpages = {46},
 url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
 doi = {10.1162/neco.1997.9.8.1735},
 acmid = {1246450},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA}
 }

 @incollection{pointer,
title = {Pointer Networks},
author = {Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2692--2700},
year = {2015},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5866-pointer-networks.pdf}
}


@article{survey,
  author    = {Pablo Hernandez{-}Leal and
               Bilal Kartal and
               Matthew E. Taylor},
  title     = {Is multiagent deep reinforcement learning the answer or the question?
               {A} brief survey},
  journal   = {CoRR},
  volume    = {abs/1810.05587},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.05587},
  archivePrefix = {arXiv},
  eprint    = {1810.05587},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1810-05587},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{lola,
  author    = {Jakob N. Foerster and
               Richard Y. Chen and
               Maruan Al{-}Shedivat and
               Shimon Whiteson and
               Pieter Abbeel and
               Igor Mordatch},
  title     = {Learning with Opponent-Learning Awareness},
  journal   = {CoRR},
  volume    = {abs/1709.04326},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.04326},
  archivePrefix = {arXiv},
  eprint    = {1709.04326},
  timestamp = {Mon, 13 Aug 2018 16:47:35 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-04326},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
